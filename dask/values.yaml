---
# nameOverride: dask
# fullnameOverride: dask

scheduler:
  name: scheduler  # Dask scheduler name.
  enabled: true  # Enable/disable scheduler.
  image:
    repository: "daskdev/dask"  # Container image repository.
    tag: 2021.12.0  # Container image tag.
    pullPolicy: IfNotPresent  # Container image pull policy.
    pullSecrets:  # Container image [pull secrets](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
    #  - name: regcred
  replicas: 1  # Number of schedulers (should always be 1).
  serviceType: "ClusterIP" # Scheduler service type. Set to `LoadBalancer` to expose outside of your cluster.
  # serviceType: "NodePort"
  # serviceType: "LoadBalancer"
  loadBalancerIP: null  # Some cloud providers allow you to specify the loadBalancerIP when using the `LoadBalancer` service type. If your cloud does not support it this option will be ignored.
  servicePort: 8786 # Scheduler service internal port.
  serviceAnnotations: {} # Scheduler service annotations.
  extraArgs: [] # Extra CLI arguments to be passed to the scheduler
    # - --preload
    # - scheduler-setup.py
  resources: {}  # Scheduler pod resources. See `values.yaml` for example values.
  #  limits:
  #    cpu: 1.8
  #    memory: 6G
  #  requests:
  #    cpu: 1.8
  #    memory: 6G
  tolerations: []  # Tolerations.
  affinity: {}  # Container affinity.
  nodeSelector: {}  # Node Selector.
  securityContext: {}  # Security Context.
  # serviceAccountName: ""
  metrics:
    enabled: false # Enable scheduler metrics. Pip package [prometheus-client](https://pypi.org/project/prometheus-client/) should be present on scheduler.
    serviceMonitor:
      enabled: false  # Enable scheduler servicemonitor.
      namespace: "" # Deploy servicemonitor in different namespace, e.g. monitoring.
      namespaceSelector: {} # Selector to select which namespaces the Endpoints objects are discovered from.
      # Default: scrape .Release.Namespace only
      # To scrape all, use the following:
      # namespaceSelector:
      #   any: true
      additionalLabels: {} # Additional labels to add to the ServiceMonitor metadata.
      interval: 30s # Interval at which metrics should be scraped.
      jobLabel: "" # The label to use to retrieve the job name from.
      targetLabels: [] # TargetLabels transfers labels on the Kubernetes Service onto the target.
      metricRelabelings: [] # MetricRelabelConfigs to apply to samples before ingestion.

webUI:
  name: webui  # Dask webui name.
  servicePort: 80 # webui service internal port.
  ingress:
    enabled: false  # Enable ingress.
    tls: false  # Ingress should use TLS.
    # secretName: dask-scheduler-tls
    hostname: dask-ui.example.com  # Ingress hostname.
    annotations:  # Ingress annotations. See `values.yaml` for example values.
      # kubernetes.io/ingress.class: "nginx"
      # secretName: my-tls-cert
      # kubernetes.io/tls-acme: "true"

worker:
  name: worker  # Dask worker name.
  image:
    repository: "daskdev/dask"  # Container image repository.
    tag: 2021.12.0  # Container image tag.
    pullPolicy: IfNotPresent  # Container image pull policy.
    dask_worker: "dask-worker"  # Dask worker command. E.g `dask-cuda-worker` for GPU worker.
    pullSecrets:  # Container image [pull secrets](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
    #  - name: regcred
  replicas: 3  # Number of workers.
  strategy:
    type: RollingUpdate  # Strategy used to replace old Pods with new ones.
  custom_scheduler_url: null # connect to already existing scheduler, deployed not by this chart.
  default_resources:  # overwritten by resource limits if they exist
    cpu: 1  # Default CPU (DEPRECATED use `resources`).
    memory: "4GiB"  # Default memory (DEPRECATED use `resources`).
  env:  # Environment variables. See `values.yaml` for example values.
  #  - name: EXTRA_APT_PACKAGES
  #    value: build-essential openssl
  #  - name: EXTRA_CONDA_PACKAGES
  #    value: numba xarray -c conda-forge
  #  - name: EXTRA_PIP_PACKAGES
  #    value: s3fs dask-ml prometheus-client --upgrade
  extraArgs: [] # Extra CLI arguments to be passed to the worker
    # - --preload
    # - worker-setup.py
  resources: {}  # Worker pod resources. See `values.yaml` for example values.
  #  limits:
  #    cpu: 1
  #    memory: 3G
  #    nvidia.com/gpu: 1
  #  requests:
  #    cpu: 1
  #    memory: 3G
  #    nvidia.com/gpu: 1
  mounts: {} # Worker Pod volumes and volume mounts, mounts.volumes follows kuberentes api v1 Volumes spec. mounts.volumeMounts follows kubernetesapi v1 VolumeMount spec
  #  volumes:
  #    - name: data
  #      emptyDir: {}
  #  volumeMounts:
  #    - name: data
  #      mountPath: /data
  annotations: {}  # Annotations
  tolerations: []  # Tolerations.
  affinity: {}  # Container affinity.
  nodeSelector: {}  # Node Selector.
  securityContext: {}  # Security Context.
  # serviceAccountName: ""
  # port: ""
  portDashboard: 8790 # Worker dashboard and metrics port.
  #  this option overrides "--nthreads" on workers, which defaults to resources.limits.cpu / default_resources.limits.cpu
  #  use it if you need to limit the amount of threads used by multicore workers, or to make workers with non-whole-number cpu limits
  # threads_per_worker: 1
  metrics:
    enabled: false # Enable workers metrics. Pip package [prometheus-client](https://pypi.org/project/prometheus-client/) should be present on workers.
    podMonitor:
      enabled: false # Enable workers podmonitor
      namespace: "" # Deploy podmonitor in different namespace, e.g. monitoring.
      namespaceSelector: {} # Selector to select which namespaces the Endpoints objects are discovered from.
      # Default: scrape .Release.Namespace only
      # To scrape all, use the following:
      # namespaceSelector:
      #   any: true
      additionalLabels: {} # Additional labels to add to the PodMonitor metadata.
      interval: 30s # Interval at which metrics should be scraped.
      jobLabel: "" # The label to use to retrieve the job name from.
      podTargetLabels: [] # PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
      metricRelabelings: [] # MetricRelabelConfigs to apply to samples before ingestion.

jupyter:
  name: jupyter  # Jupyter name.
  enabled: true  # Enable/disable the bundled Jupyter notebook.
  rbac: true  # Create RBAC service account and role to allow Jupyter pod to scale worker pods and access logs.
  image:
    repository: "daskdev/dask-notebook"  # Container image repository.
    tag: 2021.12.0  # Container image tag.
    pullPolicy: IfNotPresent  # Container image pull policy.
    pullSecrets:  # Container image [pull secrets](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
    #  - name: regcred
    #
  replicas: 1  # Number of notebook servers.
  serviceType: "ClusterIP" # Scheduler service type. Set to `LoadBalancer` to expose outside of your cluster.
  # serviceType: "NodePort"
  # serviceType: "LoadBalancer"
  servicePort: 80  # Jupyter service internal port.
  # This hash corresponds to the password 'dask'
  password: 'sha1:aae8550c0a44:9507d45e087d5ee481a5ce9f4f16f37a0867318c' # Password hash. Default hash corresponds to the password `dask`.
  env:  # Environment variables. See `values.yaml` for example values.
  #  - name: EXTRA_CONDA_PACKAGES
  #    value: "numba xarray -c conda-forge"
  #  - name: EXTRA_PIP_PACKAGES
  #    value: "s3fs dask-ml --upgrade"
  command: null  # Container command.
  args:  # Container arguments.
  #  - "start.sh"
  #  - "jupyter"
  #  - "lab"
  extraConfig: |-
    # Extra Jupyter config goes here
    # E.g
    # c.NotebookApp.port = 8888
  resources: {}  # Jupyter pod resources. See `values.yaml` for example values.
  #  limits:
  #    cpu: 2
  #    memory: 6G
  #  requests:
  #    cpu: 2
  #    memory: 6G
  mounts: {} # Worker Pod volumes and volume mounts, mounts.volumes follows kuberentes api v1 Volumes spec. mounts.volumeMounts follows kubernetesapi v1 VolumeMount spec
  #  volumes:
  #    - name: data
  #      emptyDir: {}
  #  volumeMounts:
  #    - name: data
  #      mountPath: /data
  tolerations: []  # Tolerations.
  affinity: {}  # Container affinity.
  nodeSelector: {}  # Node Selector.
  securityContext: {}  # Security Context.
  serviceAccountName: "dask-jupyter"  # Service account for use with RBAC
  ingress:
    enabled: false  # Enable ingress.
    tls: false  # Ingress should use TLS.
    # secretName: dask-jupyter-tls
    hostname: dask-jupyter.example.com  # Ingress hostname.
    annotations:  # Ingress annotations. See `values.yaml` for example values.
      # kubernetes.io/ingress.class: "nginx"
      # secretName: my-tls-cert
      # kubernetes.io/tls-acme: "true"
